{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ddcd73",
   "metadata": {},
   "source": [
    "## This notebook uses the micro-data sample from the Ghana census 2021 to construct a stratification frame, both at the district level and at the spatial unit level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b89f5",
   "metadata": {},
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470eabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cc807",
   "metadata": {},
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cffdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processed micro-data sample  \n",
    "df_census = pd.read_parquet('../data/df_census_complete.parquet') \n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read subdistricts to spatial unit mapping\n",
    "with open('../data/subdistrict_to_spatial_unit_dict.pickle', 'rb') as handle:\n",
    "    df_subdistricts = pd.read_pickle(handle).drop(columns=['polygon'])\n",
    "df_subdistricts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with RWI at the spatial unit level\n",
    "df_rwi = pd.read_csv('../data/df_rwi_unit.csv')\n",
    "df_rwi['spatial_unit'] = df_rwi['spatial_unit'].apply(shapely.wkt.loads)\n",
    "df_rwi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with averaged RWI at the district level\n",
    "df_districts_rwi = pd.read_csv('../data/df_districts_rwi.csv')\n",
    "df_districts_rwi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population density estimates at the spatial unit level\n",
    "df_pop_density = pd.read_csv('../data/gha_pop_density.csv')\n",
    "df_pop_density['spatial_unit'] = df_pop_density['spatial_unit'].apply(shapely.wkt.loads)\n",
    "df_pop_density.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17818d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe of regions and their respective populations and the districts within them\n",
    "\n",
    "def format_district_name(district: str) -> str:\n",
    "    # Remove all spaces\n",
    "    transformed_string = district.replace(' ', '')\n",
    "    \n",
    "    # Remove the trailing 'Municipal' and 'MetropolitanArea' if it exists\n",
    "    transformed_string = re.sub(r'Municipal$', '', transformed_string)\n",
    "    transformed_string = re.sub(r'MetropolitanArea\\(STMA\\)$', '', transformed_string)\n",
    "    transformed_string = re.sub(r'MetropolitanArea\\(CCMA\\)$', '', transformed_string)\n",
    "    transformed_string = re.sub(r'MetropolitanArea\\(AMA\\)$', '', transformed_string)\n",
    "    transformed_string = re.sub(r'MetropolitanArea\\(KMA\\)$', '', transformed_string)\n",
    "    transformed_string = re.sub(r'MetropolitanArea\\(TMA\\)$', '', transformed_string)\n",
    "\n",
    "    return transformed_string\n",
    "\n",
    "df_regions = pd.read_csv('../data/census_regions.csv')\n",
    "df_regions['population'] = df_regions['population'].apply(lambda x: int(str(x).replace(',', '')))\n",
    "df_regions['districts']= df_regions.drop(columns=['region', 'population']).values.tolist()\n",
    "df_regions = df_regions[['region', 'population', 'districts']]\n",
    "df_regions['districts'] = df_regions['districts'].apply(lambda y: [format_district_name(x) for x in y if str(x) != 'nan'])\n",
    "df_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d50a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_regions)):\n",
    "    print(df_regions.loc[i,'districts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a358e1",
   "metadata": {},
   "source": [
    "# 2. Create Stratification Frame at the District Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df_census.groupby([\n",
    "    'District', \n",
    "    'Age',\n",
    "    'Female',\n",
    "    'SchoolMiddleSchoolOrGreater', \n",
    "    'RWI', \n",
    "    'NDC_%', \n",
    "    'NPP_%', \n",
    "    'Age_coded'\n",
    "]).sum()\n",
    "\n",
    "grouped_data.reset_index().to_csv('../data/outputs/df_stratification_frame.csv', index=False)\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9096ebfb",
   "metadata": {},
   "source": [
    "# 3. Create Stratification Frame at the Spatial Unit Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9372e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RWI since it's at the district level and Age coded \n",
    "df_census_i = df_census.drop(columns=['RWI', 'Age_coded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average covariates by district  \n",
    "df_grouped = df_census_i.groupby('District', as_index=False)[['Age', 'Female',\n",
    "                                          'SchoolMiddleSchoolOrGreater',\n",
    "                                          'NDC_%', 'NPP_%']].mean()\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9800b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge spatial units to micro-data by district\n",
    "df_subdistricts_i = df_subdistricts.merge(df_grouped, how='left', left_on='subdistrict', right_on='District').drop(columns=['subdistrict'])\n",
    "df_subdistricts_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef540b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RWI at the spatial unit level\n",
    "df_subdistricts_rwi = df_subdistricts_i.merge(df_rwi, how='left', on='spatial_unit')\n",
    "df_subdistricts_rwi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19058ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge district-level RWIs to the rwi column for spatial units that do not have an RWI\n",
    "df_subdistricts_rwi_ = df_subdistricts_rwi.merge(df_districts_rwi, how='left', on='District')\n",
    "df_subdistricts_rwi_['RWI_x'] = df_subdistricts_rwi_['RWI_x'].fillna(df_subdistricts_rwi_['RWI_y'])\n",
    "df_subdistricts_rwi_ = df_subdistricts_rwi_.drop(columns=['RWI_y'])\n",
    "df_subdistricts_rwi_ = df_subdistricts_rwi_.rename(columns={'RWI_x': 'RWI'})\n",
    "\n",
    "df_subdistricts_rwi_.to_csv('../data/outputs/df_stratification_frame_unit.csv', index=False)\n",
    "df_subdistricts_rwi_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11453c",
   "metadata": {},
   "source": [
    "# 4. Get Population Estimates across Stratum for each Spatial Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40199d48",
   "metadata": {},
   "source": [
    "In this section, we use the stratification frame at the spatial unit level and the population estimates at the spatial unit level to get population estimates across each stratum for every spatial unit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge population estimates to each spatial unit\n",
    "df_subdistricts_rwi_ = df_subdistricts_rwi_.merge(df_pop_density[['spatial_unit', 'pop_2020']], how='left', on='spatial_unit')\n",
    "df_subdistricts_rwi_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beedd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spatial unit population average across all districts and fill in NaN values in pop_2020 column with the district average\n",
    "df_pop_avgs = df_subdistricts_rwi_.groupby('District', as_index=False)['pop_2020'].mean().rename(columns={'pop_2020': 'pop_2020_avg'})\n",
    "df_subdistricts_rwi_ = df_subdistricts_rwi_.merge(df_pop_avgs, how='left', on='District')\n",
    "df_subdistricts_rwi_['pop_2020'] = df_subdistricts_rwi_['pop_2020'].fillna(df_subdistricts_rwi_['pop_2020_avg'])\n",
    "df_subdistricts_rwi_ = df_subdistricts_rwi_.drop(columns=['pop_2020_avg'])\n",
    "df_subdistricts_rwi_.to_csv('../data/outputs/df_stratification_frame_unit_population.csv', index=False)\n",
    "df_subdistricts_rwi_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_unit_population(spatial_unit):\n",
    "    \"\"\"\n",
    "    Helper function to get population estimate and ID of spatial unit.\n",
    "\n",
    "    Parameters:\n",
    "        spatial_unit: Spatial unit object (Polygon object)\n",
    "\n",
    "    Returns:\n",
    "        pop: Population count of the spatial unit.\n",
    "        ID: ID of the spatial unit.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        # get population count of spatial unit\n",
    "        pop = df_pop_density[df_pop_density['spatial_unit'] == spatial_unit]['pop_2020'].values[0]\n",
    "\n",
    "        # get ID of spatial unit\n",
    "        ID = df_pop_density[df_pop_density['spatial_unit'] == spatial_unit]['ID'].values[0]\n",
    "        \n",
    "    except:\n",
    "        return False \n",
    "    \n",
    "    return (pop, ID)\n",
    "\n",
    "\n",
    "def get_spatial_units(district: str):\n",
    "    \"\"\"\n",
    "    Helper function to get the spatial units associated with GADN region.\n",
    "\n",
    "    Parameters:\n",
    "        district: A string indicating the district.\n",
    "\n",
    "    Returns:\n",
    "        spatial_units: A list spatial unit (Polygon object) associated with the district.\n",
    "    \"\"\"\n",
    "    spatial_units = df_subdistricts[df_subdistricts['subdistrict'] == district]['spatial_unit'].values.tolist()\n",
    "    \n",
    "    return spatial_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73533ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each district, calculate the population estimates for each stratum at the spatial unit level \n",
    "total_population_dict = {}  # Dictionary to store total population for each subregion\n",
    "\n",
    "grouped_data = grouped_data.reset_index()\n",
    "for d in grouped_data.District.unique():\n",
    "    subregion_group = grouped_data[grouped_data['District'] == d]\n",
    "    subregion_weights = (subregion_group['Weight'] / subregion_group['Weight'].sum()).values\n",
    "    est_pop_dict = {}\n",
    "    for unit in get_spatial_units(d):\n",
    "        if not get_spatial_unit_population(unit): \n",
    "            continue\n",
    "        total_population, ID = get_spatial_unit_population(unit)\n",
    "        est_pop_dict[str(ID)] = subregion_weights * total_population\n",
    "        \n",
    "    df_subregion = pd.concat([subregion_group.reset_index(), pd.DataFrame(est_pop_dict.values()).T], ignore_index=True, axis=1)\n",
    "    df_subregion.columns = subregion_group.reset_index().columns.tolist() + [\"est_pop_\" + k for k in est_pop_dict.keys()]\n",
    "    df_subregion = df_subregion.drop(columns=['index'])\n",
    "    \n",
    "    # save each district as a new dataframe \n",
    "    df_subregion.to_parquet(\"../data/outputs/district_dfs/\" + d.replace('-','')) # choose folder name\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073c91b",
   "metadata": {},
   "source": [
    "# 5. Population Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify population counts with district and region\n",
    "\n",
    "# Define the folder path containing the Parquet files\n",
    "folder_path = '../data/outputs/district_dfs/'\n",
    "\n",
    "# List of columns to exclude from summing\n",
    "columns_to_exclude = ['Age', 'Female', 'SchoolMiddleSchoolOrGreater', 'Weight', 'RWI', 'NDC_%', 'NPP_%', 'Age_coded', 'District'] \n",
    "\n",
    "# Initialize an empty DataFrame to store the sum results\n",
    "sum_results = {}\n",
    "\n",
    "# Iterate through all Parquet files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    parquet_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Read the Parquet file into a DataFrame\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "    # Calculate the sum across all columns (except excluded columns)\n",
    "    sum_df = df.drop(columns=columns_to_exclude).sum().sum()\n",
    "\n",
    "    # Append the sum results to the sum_results DataFrame\n",
    "    sum_results[filename] = sum_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b37661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_district_string(input_string):\n",
    "#     if input_string == \"Komenda Edina Eguafo Abirem Municipal\":\n",
    "#         return 'Komenda-Edina-Eguafo-Abirem-'\n",
    "    \n",
    "#     if input_string == 'Abura Asebu Kwamankese':\n",
    "#         return 'Abura-Asebu-Kwamankese'\n",
    "\n",
    "#     # Replace '/' with '-'\n",
    "#     replaced_string = input_string.replace('-', '')\n",
    "#     replaced_string = replaced_string.replace('/', '-')\n",
    "    \n",
    "#     # Remove all spaces\n",
    "#     transformed_string = replaced_string.replace(' ', '')\n",
    "    \n",
    "#     # Remove the trailing 'Municipal' and 'MetropolitanArea(STMA)' if it exists\n",
    "#     result_string = re.sub(r'Municipal$', '', transformed_string)\n",
    "#     result_string = re.sub(r'MetropolitanArea\\(STMA\\)$', '', result_string)\n",
    "#     result_string = re.sub(r'MetropolitanArea\\(CCMA\\)$', '', result_string)\n",
    "    \n",
    "#     return result_string\n",
    "\n",
    "# Region population validation\n",
    "for i, r in df_regions.iterrows(): \n",
    "    summed_pop = 0\n",
    "    for district in r['districts']:\n",
    "        print(district)\n",
    "        # summed_pop += sum_results[convert_district_string(district)]\n",
    "        # summed_pop += sum_results[district.replace(\"/\", \"&\")]\n",
    "        summed_pop += sum_results[district]\n",
    "    \n",
    "    actual_pop = r['population']\n",
    "    print(r['region'], \"\\nActual:\", actual_pop, \"\\nEstimated:\", round(summed_pop), \"\\n% change: \" + str(round(((summed_pop - actual_pop) / summed_pop)*100, 2)) + \"%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
